# tools/predict_one.py
import os, argparse, torch
from src.tokenizer import Tokenizer
from src.crnn_model import CRNN
from src.dataset import LineDataset

CKPT   = os.path.join("runs","crnn","rigveda_s1_crnn_best.pt")
LABELS = os.path.join("labels","classes_vedic.json")

def ctc_collapse(ids, blank_idx):
    out=[]
    for s in ids:
        if s==blank_idx:
            continue
        if not out or s!=out[-1]:
            out.append(s)
    return out

def find_index_by_basename(transcripts_path: str, target_basename: str):
    target_basename = os.path.basename(target_basename)
    with open(transcripts_path, "r", encoding="utf-8") as f:
        for idx, line in enumerate(f):
            # line format: images/XXXX.png<TAB>text
            left = line.split("\t", 1)[0].strip()
            if os.path.basename(left) == target_basename:
                return idx
    return None

def main(img_path: str, split: str):
    # split is "train" or "val"
    root = os.path.join("data","S1_clean", split)
    transcripts = os.path.join(root, "transcripts.txt")
    idx = find_index_by_basename(transcripts, img_path)
    if idx is None:
        raise SystemExit(f"Image {img_path} not found in {transcripts}. "
                         f"Use an image generated by your dataset (so preprocessing matches).")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    tok = Tokenizer(LABELS)
    model = CRNN(num_classes=len(tok.tokens)).to(device)
    model.load_state_dict(torch.load(CKPT, map_location=device))
    model.eval()

    ds = LineDataset(root)               # exact same preprocessing as training
    x, gt = ds[idx]                      # (1,H,W) tensor already normalized/padded
    x = x.unsqueeze(0).to(device)        # (1,1,H,W)

    with torch.no_grad():
        lp = model(x)                    # (1,T,C)
        ids_t = lp[0].argmax(dim=-1).cpu().tolist()
        ids = ctc_collapse(ids_t, tok.blank_index)
        pred = tok.ids_to_text(ids)

    print(f"GT : {gt}")
    print(f"PD : {pred}")

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--img", required=True, help="path to a dataset image (e.g., data\\S1_clean\\val\\images\\0001_f00_r00.png)")
    ap.add_argument("--split", default="val", choices=["train","val"], help="dataset split containing the image")
    args = ap.parse_args()
    main(args.img, args.split)
